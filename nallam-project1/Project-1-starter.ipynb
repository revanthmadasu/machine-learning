{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "62834763",
      "metadata": {
        "id": "62834763"
      },
      "source": [
        "# Project 1 Starter\n",
        "\n",
        "**This is draft - version 0 - changes are possible and will be anounced.**\n",
        "\n",
        "Project 1 is to allow students to practice Data Science concepts learned so far.\n",
        "\n",
        "The project will include following tasks:\n",
        "- Load dataset. Don't use \"index\" column for training.\n",
        "- Clean up the data:\n",
        "    - Encode replace missing values\n",
        "    - Replace features values that appear incorrect\n",
        "- Encode categorical variables\n",
        "- Split dataset to Train/Validation/Test\n",
        "- Add engineered features\n",
        "- Train and tune ML model\n",
        "- Provide final metrics using Test dataset\n",
        "\n",
        "### Types of models to train\n",
        "\n",
        "Your final submission should include single model. \n",
        "The model set you should try to come up with best model:\n",
        "1. Sklearn Logistic Regression - try all combinations of regularization\n",
        "2. H2O-3 GLM - try different combinations of regularization\n",
        "\n",
        "\n",
        "\n",
        "### Feature engineering\n",
        "\n",
        "You should train/fit categorical features scalers and encoders on Train only. Use `transform` or equivalent function on Validation/Test datasets.\n",
        "\n",
        "It is important to understand all the steps before model training, so that you can reliably replicate and test them to produce scoring function.\n",
        "\n",
        "\n",
        "You should generate various new features. Examples of such features can be seen in the Module-3 lecture on GLMs.\n",
        "Your final model should have at least **10** new engineered features. On-hot-encoding, label encoding, and target encoding is not included in the **10** features.\n",
        "You can try, but target encoding is not expected to produce improvement for Linear models.\n",
        "\n",
        "Ideas for Feature engineering for various types of variables:\n",
        "1. https://docs.h2o.ai/driverless-ai/1-10-lts/docs/userguide/transformations.html\n",
        "2. GLM lecture and hands-on (Module-3)\n",
        "\n",
        "\n",
        "**Note**: \n",
        "- You don't have to perform feature engineering using H2O-3 even if you decided to use H2O-3 GLM for model training.\n",
        "- It is OK to perfor feature engineering using any technique, as long as you can replicate it correctly in the Scoring function.\n",
        "\n",
        "\n",
        "### Threshold calculation\n",
        "\n",
        "You will need to calculate optimal threshold for class assignment using F1 metric:\n",
        "- If using sklearn, use F1 `macro`: `f1_score(y_true, y_pred, average='macro')` \n",
        "- If using H2O-3, use F1\n",
        "\n",
        "You will need to find optimal probability threshold for class assignment, the threshold that maximizes above F1.\n",
        "\n",
        "\n",
        "\n",
        "### Scoring function\n",
        "\n",
        "The Project-1 will be graded based on the completeness and performance of your final model against the hold-out dataset.\n",
        "The hold-out dataset will not be known to the students. As part of your deliverables, you will need to submit a scoring function. The scoring function will perform the following:\n",
        "- Accept dataset in the same format as provided with the project, minus \"MIS_Status\" column\n",
        "- Load trained model and any encoders/scalers that are needed to transform data\n",
        "- Transform dataset into format that can be scored with the trained model\n",
        "- Score the dataset and return the results, for each record\n",
        "    - Record ID\n",
        "    - Record label as determined by final model (0 or 1)\n",
        "    - If your model returns probabilities, you need to assign the label based on maximum F1 threshold\n",
        "    \n",
        "Scoring function header:\n",
        "```\n",
        "def project_1_scoring(data):\n",
        "    \"\"\"\n",
        "    Function to score input dataset.\n",
        "    \n",
        "    Input: dataset in Pandas DataFrame format\n",
        "    Output: Python list of labels in the same order as input records\n",
        "    \n",
        "    Flow:\n",
        "        - Load artifacts\n",
        "        - Transform dataset\n",
        "        - Score dataset\n",
        "        - Return labels\n",
        "    \n",
        "    \"\"\"\n",
        "    l = data.shape[0]\n",
        "    return l*[0]\n",
        "```\n",
        "\n",
        "Look for full example of scoring function at the bottom of the notebook. **Don't copy as is - this is just an example**\n",
        "\n",
        "\n",
        "\n",
        "### Deliverables in a single zip file in the following structure:\n",
        "- `notebook` (folder)\n",
        "    - Jupyter notebook with complete code to manipulate data, train and tune final model. `ipynb` format\n",
        "    - Jupyter notebook in `html` format\n",
        "- `artifacts` (folder)\n",
        "    - Model and any potential encoders in the \"pkl\" format or native H2O-3 format (for H2O-3 model)\n",
        "    - Scoring function that will load the final model and encoders. Separate from above notebook or `.py` file\n",
        "\n",
        "\n",
        "\n",
        "Your notebook should include explanations about your code and be designed to be easily followed and results replicated. Once you are done with the final version, you will need to test it by running all cells from top to bottom after restarting Kernel. It can be done by running `Kernel -> Restart & Run All`\n",
        "\n",
        "\n",
        "**Important**: To speed up progress, first produce working code using a small subset of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dbeaf5cb",
      "metadata": {
        "id": "dbeaf5cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6e1cd3-3fee-41d6-8653-8248db3eff8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install category-encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRpMqjRokZqp",
        "outputId": "504c4d4d-99e5-4396-d1a0-3dd0af6117dc"
      },
      "id": "oRpMqjRokZqp",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: category-encoders in /usr/local/lib/python3.9/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from category-encoders) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.9/dist-packages (from category-encoders) (1.4.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from category-encoders) (1.10.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from category-encoders) (0.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from category-encoders) (0.13.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from category-encoders) (1.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category-encoders) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category-encoders) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category-encoders) (1.1.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.9.0->category-encoders) (23.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c341cb74",
      "metadata": {
        "id": "c341cb74"
      },
      "source": [
        "## Dataset description\n",
        "\n",
        "The dataset is from the U.S. Small Business Administration (SBA) The U.S. SBA was founded in 1953 on the principle of promoting and assisting small enterprises in the U.S. credit market (SBA Overview and History, US Small Business Administration (2015)). Small businesses have been a primary source of job creation in the United States; therefore, fostering small business formation and growth has social benefits by creating job opportunities and reducing unemployment. There have been many success stories of start-ups receiving SBA loan guarantees such as FedEx and Apple Computer. However, there have also been stories of small businesses and/or start-ups that have defaulted on their SBA-guaranteed loans.  \n",
        "More info on the original dataset: https://www.kaggle.com/mirbektoktogaraev/should-this-loan-be-approved-or-denied\n",
        "\n",
        "**Don't use original dataset, use only dataset provided with project requirements in eLearning**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c9b618",
      "metadata": {
        "id": "a0c9b618"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Use dataset provided in the eLearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3ca7e035",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3ca7e035",
        "outputId": "e525d346-f32e-474c-8289-e30a83e8041e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 1500)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Extend cell width\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eb889838",
      "metadata": {
        "id": "eb889838"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Created on Mon Mar 18 18:25:50 2019\n",
        "\n",
        "@author: Uri Smashnov\n",
        "\n",
        "Purpose: Analyze input Pandas DataFrame and return stats per column\n",
        "Details: The function calculates levels for categorical variables and allows to analyze summarized information\n",
        "\n",
        "To view wide table set following Pandas options:\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('max_colwidth',200)\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "def describe_more(df,normalize_ind=False, weight_column=None, skip_columns=[], dropna=True):\n",
        "    var = [] ; l = [] ; t = []; unq =[]; min_l = []; max_l = [];\n",
        "    assert isinstance(skip_columns, list), \"Argument skip_columns should be list\"\n",
        "    if weight_column is not None:\n",
        "        if weight_column not in list(df.columns):\n",
        "            raise AssertionError('weight_column is not a valid column name in the input DataFrame')\n",
        "      \n",
        "    for x in df:\n",
        "        if x in skip_columns:\n",
        "            pass\n",
        "        else:\n",
        "            var.append( x )\n",
        "            uniq_counts = len(pd.value_counts(df[x],dropna=dropna))\n",
        "            uniq_counts = len(pd.value_counts(df[x], dropna=dropna)[pd.value_counts(df[x],dropna=dropna)>0])\n",
        "            l.append(uniq_counts)\n",
        "            t.append( df[ x ].dtypes )\n",
        "            min_l.append(df[x].apply(str).str.len().min())\n",
        "            max_l.append(df[x].apply(str).str.len().max())\n",
        "            if weight_column is not None and x not in skip_columns:\n",
        "                df2 = df.groupby(x).agg({weight_column: 'sum'}).sort_values(weight_column, ascending=False)\n",
        "                df2['authtrans_vts_cnt']=((df2[weight_column])/df2[weight_column].sum()).round(2)\n",
        "                unq.append(df2.head(n=100).to_dict()[weight_column])\n",
        "            else:\n",
        "                df_cat_d = df[x].value_counts(normalize=normalize_ind,dropna=dropna).round(decimals=2)\n",
        "                df_cat_d = df_cat_d[df_cat_d>0]\n",
        "                #unq.append(df[x].value_counts().iloc[0:100].to_dict())\n",
        "                unq.append(df_cat_d.iloc[0:100].to_dict())\n",
        "            \n",
        "    levels = pd.DataFrame( { 'A_Variable' : var , 'Levels' : l , 'Datatype' : t ,\n",
        "                             'Min Length' : min_l,\n",
        "                             'Max Length': max_l,\n",
        "                             'Level_Values' : unq} )\n",
        "    #levels.sort_values( by = 'Levels' , inplace = True )\n",
        "    return levels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cee2c254",
      "metadata": {
        "id": "cee2c254"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a19bd163",
      "metadata": {
        "id": "a19bd163"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('./data/SBA_loans_project_1.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2301a5ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2301a5ed",
        "outputId": "ecef4c98-f7c9-4317-8a06-eeff7399d838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (809247, 21)\n"
          ]
        }
      ],
      "source": [
        "print(\"Data shape:\", data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab8b4aea",
      "metadata": {
        "id": "ab8b4aea"
      },
      "source": [
        "**Review dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "547f9eb1",
      "metadata": {
        "id": "547f9eb1"
      },
      "outputs": [],
      "source": [
        "desc_df = describe_more(data)\n",
        "desc_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fe1af41",
      "metadata": {
        "id": "5fe1af41"
      },
      "source": [
        "## Dataset preparation and clean-up\n",
        "\n",
        "Modify and clean-up the dataset as following:\n",
        "- Replace encode Na/Null values\n",
        "- Convert the strings styled as '$XXXX.XX' to float values. Columns = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
        "- Convert MIS_Status to 0/1. Make value \"CHGOFF\" as 1\n",
        "\n",
        "Any additional clean-up as you find fit."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing duplicates\n",
        "data = data.drop_duplicates()\n",
        "print(\"Data shape:\", data.shape)"
      ],
      "metadata": {
        "id": "ZaRa4KNm0iEy",
        "outputId": "fa3a9fa5-0c67-4efb-92a6-0aeb9923b2c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZaRa4KNm0iEy",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (809247, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0f9f9eaa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f9f9eaa",
        "outputId": "5b7a504e-83c3-4905-9f21-f240f21c0d3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "City                                  GLEN BURNIE\n",
              "State                                          MD\n",
              "Zip                                         21060\n",
              "Bank                 BUSINESS FINANCE GROUP, INC.\n",
              "BankState                                      VA\n",
              "NAICS                                      811111\n",
              "Term                                          240\n",
              "NoEmp                                           7\n",
              "NewExist                                      1.0\n",
              "CreateJob                                       6\n",
              "RetainedJob                                     7\n",
              "FranchiseCode                                   1\n",
              "UrbanRural                                      1\n",
              "RevLineCr                                       0\n",
              "LowDoc                                          N\n",
              "DisbursementGross                        743000.0\n",
              "BalanceGross                                  0.0\n",
              "GrAppv                                   743000.0\n",
              "SBA_Appv                                 743000.0\n",
              "MIS_Status                                  P I F\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# remove index\n",
        "processed_data = data.loc[:,data.columns!='index']\n",
        "def dollar_string_to_float(dollar_str):\n",
        "  dollar_str = dollar_str.replace(',', '')\n",
        "  dollar_float = float(dollar_str[1:])\n",
        "  return dollar_float\n",
        "currency_cols = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
        "for colname in currency_cols:\n",
        "  processed_data[colname] = processed_data[colname].apply(dollar_string_to_float)\n",
        "processed_data.loc[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data['MIS_Status'] = processed_data['MIS_Status'].replace('P I F', 0)\n",
        "processed_data['MIS_Status'] = processed_data['MIS_Status'].replace('CHGOFF', 1)\n",
        "# processed_data = processed_data.dropna(subset='MIS_Status')\n",
        "processed_data = processed_data.dropna()\n",
        "processed_data['MIS_Status'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJlBnwrPvIg4",
        "outputId": "5ebb3a13-f8d6-42bc-fd32-07e71ba006e4"
      },
      "id": "WJlBnwrPvIg4",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data.info()"
      ],
      "metadata": {
        "id": "PK_OOX3d7U3W",
        "outputId": "80716ab0-92ad-4401-b02f-eb852ef5fb42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PK_OOX3d7U3W",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 784130 entries, 0 to 809246\n",
            "Data columns (total 20 columns):\n",
            " #   Column             Non-Null Count   Dtype   \n",
            "---  ------             --------------   -----   \n",
            " 0   City               784130 non-null  category\n",
            " 1   State              784130 non-null  category\n",
            " 2   Zip                784130 non-null  int64   \n",
            " 3   Bank               784130 non-null  category\n",
            " 4   BankState          784130 non-null  category\n",
            " 5   NAICS              784130 non-null  int64   \n",
            " 6   Term               784130 non-null  int64   \n",
            " 7   NoEmp              784130 non-null  int64   \n",
            " 8   NewExist           784130 non-null  float64 \n",
            " 9   CreateJob          784130 non-null  int64   \n",
            " 10  RetainedJob        784130 non-null  int64   \n",
            " 11  FranchiseCode      784130 non-null  int64   \n",
            " 12  UrbanRural         784130 non-null  int64   \n",
            " 13  RevLineCr          784130 non-null  category\n",
            " 14  LowDoc             784130 non-null  category\n",
            " 15  DisbursementGross  784130 non-null  float64 \n",
            " 16  BalanceGross       784130 non-null  float64 \n",
            " 17  GrAppv             784130 non-null  float64 \n",
            " 18  SBA_Appv           784130 non-null  float64 \n",
            " 19  MIS_Status         784130 non-null  float64 \n",
            "dtypes: category(6), float64(6), int64(8)\n",
            "memory usage: 97.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# handling null data\n",
        "row_null_counts = processed_data.isna().any(axis=1).sum()\n",
        "print(\"\\nNumber of rows with null values:\", row_null_counts)\n",
        "def check_null_counts():\n",
        "  col_null_counts = dict()\n",
        "  for column in processed_data.columns:\n",
        "    col_null_count = processed_data[column].isna().sum()\n",
        "    if col_null_count:\n",
        "      col_null_counts[column] = col_null_count\n",
        "  return col_null_counts\n",
        "print(f'before handling: {check_null_counts()}')\n",
        "categoral_null_cols = ['City', 'State', 'Bank', 'BankState', 'RevLineCr', 'LowDoc']\n",
        "for null_cat_col in categoral_null_cols:\n",
        "  processed_data[null_cat_col] = processed_data[null_cat_col].fillna('unknown').astype('category')\n",
        "processed_data['NewExist'] = processed_data['NewExist'].fillna(0)\n",
        "print(f'after handling handling: {check_null_counts()}')"
      ],
      "metadata": {
        "id": "WnHdYBCm1gt9",
        "outputId": "846732f1-40ad-4d88-8dfc-aa5858ea36a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WnHdYBCm1gt9",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of rows with null values: 0\n",
            "before handling: {}\n",
            "after handling handling: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data['MIS_Status'].value_counts()"
      ],
      "metadata": {
        "id": "4WzV6vja7o80",
        "outputId": "efdaeab7-28f3-4df9-a1ab-264055ead8d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4WzV6vja7o80",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    658734\n",
              "1.0    140776\n",
              "Name: MIS_Status, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data['RevLineCr'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq5z2iL9J_aN",
        "outputId": "8bf8637a-1875-4d03-a640-66607f546d4c"
      },
      "id": "Wq5z2iL9J_aN",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N    374421\n",
              "0    231797\n",
              "Y    179628\n",
              "T     13606\n",
              "1        22\n",
              "R        12\n",
              "`         9\n",
              "2         6\n",
              "C         2\n",
              "-         1\n",
              ".         1\n",
              "3         1\n",
              "5         1\n",
              "7         1\n",
              "A         1\n",
              "Q         1\n",
              "Name: RevLineCr, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'before: {processed_data['RevLineCr'].value_counts()}')\n",
        "processed_data['RevLineCr'] = processed_data['RevLineCr'].replace('N', 0)\n",
        "processed_data['RevLineCr'] = processed_data['RevLineCr'].replace('0', 0)\n",
        "processed_data['RevLineCr'] = processed_data['RevLineCr'].replace('Y', 1)\n",
        "for remove_cat in processed_data['RevLineCr'].cat.categories.tolist():\n",
        "  if remove_cat not in [0,1]:\n",
        "    processed_data = processed_data[processed_data['RevLineCr'] != remove_cat]\n",
        "    processed_data['RevLineCr'] = processed_data['RevLineCr'].cat.remove_categories(remove_cat)\n",
        "\n",
        "processed_data['RevLineCr'].value_counts()"
      ],
      "metadata": {
        "id": "0VN0Jlns7nbI",
        "outputId": "b23251b4-66e2-43bb-cce0-f1cd03bad71c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0VN0Jlns7nbI",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    606218\n",
              "1    179628\n",
              "Name: RevLineCr, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data['MIS_Status'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BybhXgPUpcls",
        "outputId": "6566bac8-7a61-4a80-96af-e72d7d03b4b5"
      },
      "id": "BybhXgPUpcls",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data['NewExist'] = processed_data['NewExist'].replace(1, 0)\n",
        "processed_data['NewExist'] = processed_data['NewExist'].replace(2, 1)\n",
        "processed_data['RevLineCr'].value_counts()\n",
        "# processed_data['RevLineCr'].cat.categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5LkmHUXIHgz",
        "outputId": "ea98a494-ef72-45e8-d176-e014a5c9b906"
      },
      "id": "S5LkmHUXIHgz",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    606218\n",
              "1    179628\n",
              "Name: RevLineCr, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data['LowDoc'] = processed_data['LowDoc'].replace('Y', 1)\n",
        "processed_data['LowDoc'] = processed_data['LowDoc'].replace('N', 0)\n",
        "processed_data['LowDoc'] = processed_data['LowDoc'].replace('0', 0)\n",
        "processed_data['LowDoc'] = processed_data['LowDoc'].replace('1', 1)\n",
        "for remove_cat in processed_data['LowDoc'].cat.categories.tolist():\n",
        "  if remove_cat not in [0,1]:\n",
        "    processed_data = processed_data[processed_data['LowDoc'] != remove_cat]\n",
        "    processed_data['LowDoc'] = processed_data['LowDoc'].cat.remove_categories(remove_cat)\n",
        "processed_data['LowDoc'].value_counts()\n",
        "# processed_data['LowDoc'].cat.categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW0fau1kTVlF",
        "outputId": "dd2286fb-0b55-498c-fff7-1fbf46f48b19"
      },
      "id": "LW0fau1kTVlF",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    686998\n",
              "1     97132\n",
              "Name: LowDoc, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data['UrbanRural'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gtJRjhxqJkG",
        "outputId": "c32b709d-50be-4fd4-9e01-722aeebc4553"
      },
      "id": "1gtJRjhxqJkG",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    408049\n",
              "0    284083\n",
              "2     91998\n",
              "Name: UrbanRural, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data.info()"
      ],
      "metadata": {
        "id": "7Ybqm9Oo_5MH",
        "outputId": "8a853e8a-cb41-4f8f-9ab5-aa0622ff2401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7Ybqm9Oo_5MH",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 784130 entries, 0 to 809246\n",
            "Data columns (total 20 columns):\n",
            " #   Column             Non-Null Count   Dtype   \n",
            "---  ------             --------------   -----   \n",
            " 0   City               784130 non-null  category\n",
            " 1   State              784130 non-null  category\n",
            " 2   Zip                784130 non-null  int64   \n",
            " 3   Bank               784130 non-null  category\n",
            " 4   BankState          784130 non-null  category\n",
            " 5   NAICS              784130 non-null  int64   \n",
            " 6   Term               784130 non-null  int64   \n",
            " 7   NoEmp              784130 non-null  int64   \n",
            " 8   NewExist           784130 non-null  float64 \n",
            " 9   CreateJob          784130 non-null  int64   \n",
            " 10  RetainedJob        784130 non-null  int64   \n",
            " 11  FranchiseCode      784130 non-null  int64   \n",
            " 12  UrbanRural         784130 non-null  int64   \n",
            " 13  RevLineCr          784130 non-null  category\n",
            " 14  LowDoc             784130 non-null  category\n",
            " 15  DisbursementGross  784130 non-null  float64 \n",
            " 16  BalanceGross       784130 non-null  float64 \n",
            " 17  GrAppv             784130 non-null  float64 \n",
            " 18  SBA_Appv           784130 non-null  float64 \n",
            " 19  MIS_Status         784130 non-null  float64 \n",
            "dtypes: category(6), float64(6), int64(8)\n",
            "memory usage: 97.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7f21dcf",
      "metadata": {
        "id": "b7f21dcf"
      },
      "source": [
        "## Categorical and numerical variables encoding\n",
        "\n",
        "Encode categorical variables using either one of the techniques below. Don't use LabelEncoder.\n",
        "- One-hot-encoder for variables with less than 10 valid values. Name your new columns \"Original_name\"_valid_value\n",
        "- Target encoder from the following library: https://contrib.scikit-learn.org/category_encoders/index.html . Name your new column \"Original_name\"_trg\n",
        "- WOE encoder from the following library: https://contrib.scikit-learn.org/category_encoders/index.html . Name your new column \"Original_name\"_woe\n",
        "\n",
        "\n",
        "WOE encoder can be used with numerical variables too. \n",
        "\n",
        "\n",
        "Example of use for target encoder:\n",
        "```\n",
        "import category_encoders as ce\n",
        "\n",
        "encoder = ce.TargetEncoder(cols=[...])\n",
        "\n",
        "encoder.fit(X, y)\n",
        "X_cleaned = encoder.transform(X_dirty)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_processed_data = processed_data.sample(frac=0.0125, random_state=27)\n",
        "s_processed_data\n",
        "print(s_processed_data.shape)"
      ],
      "metadata": {
        "id": "2ZiIsG0dMK6Y",
        "outputId": "20fd9800-29f7-4560-8206-b5166bab161b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2ZiIsG0dMK6Y",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9802, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = []\n",
        "cat_cols_bin_en = ['City', 'State', 'Bank', 'BankState', 'Zip', 'NAICS', 'UrbanRural']"
      ],
      "metadata": {
        "id": "B7vmNtvgWHvY"
      },
      "id": "B7vmNtvgWHvY",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_processed_data.info()"
      ],
      "metadata": {
        "id": "e1daKaVu-nIv",
        "outputId": "31d326e9-74d6-434a-a880-a0b096211065",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "e1daKaVu-nIv",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3921 entries, 724290 to 635320\n",
            "Data columns (total 20 columns):\n",
            " #   Column             Non-Null Count  Dtype   \n",
            "---  ------             --------------  -----   \n",
            " 0   City               3921 non-null   category\n",
            " 1   State              3921 non-null   category\n",
            " 2   Zip                3921 non-null   int64   \n",
            " 3   Bank               3921 non-null   category\n",
            " 4   BankState          3921 non-null   category\n",
            " 5   NAICS              3921 non-null   int64   \n",
            " 6   Term               3921 non-null   int64   \n",
            " 7   NoEmp              3921 non-null   int64   \n",
            " 8   NewExist           3921 non-null   float64 \n",
            " 9   CreateJob          3921 non-null   int64   \n",
            " 10  RetainedJob        3921 non-null   int64   \n",
            " 11  FranchiseCode      3921 non-null   int64   \n",
            " 12  UrbanRural         3921 non-null   int64   \n",
            " 13  RevLineCr          3921 non-null   category\n",
            " 14  LowDoc             3921 non-null   category\n",
            " 15  DisbursementGross  3921 non-null   float64 \n",
            " 16  BalanceGross       3921 non-null   float64 \n",
            " 17  GrAppv             3921 non-null   float64 \n",
            " 18  SBA_Appv           3921 non-null   float64 \n",
            " 19  MIS_Status         3921 non-null   float64 \n",
            "dtypes: category(6), float64(6), int64(8)\n",
            "memory usage: 1.9 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "encoder = OneHotEncoder(handle_unknown = 'ignore', sparse=False)\n",
        "encoder.fit(s_processed_data[cat_cols])\n",
        "def oneHotTransformX(data, encoder): \n",
        "  data_encoded = encoder.transform(data[cat_cols])\n",
        "  feature_names = encoder.get_feature_names_out(cat_cols)\n",
        "  # data_encoded_df = pd.DataFrame.sparse.from_spmatrix(data_encoded, columns=encoder.get_feature_names_out(cat_cols))\n",
        "  df_encoded_df = pd.DataFrame(data_encoded, columns=feature_names)\n",
        "  return df_encoded_df\n",
        "onehot_encoded_data = oneHotTransformX(s_processed_data, encoder)\n",
        "  "
      ],
      "metadata": {
        "id": "UZD9CM1W9CmQ"
      },
      "id": "UZD9CM1W9CmQ",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoded_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOsQCn5tJDLc",
        "outputId": "5aede3a6-9e15-4df0-9ef3-aaaec6e7dba2"
      },
      "id": "oOsQCn5tJDLc",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concated_df = pd.concat([onehot_encoded_data, s_processed_data])\n",
        "concated_df = concated_df.loc[:,concated_df.columns!='UrbanRural']"
      ],
      "metadata": {
        "id": "MqFNaj7gmdl6"
      },
      "id": "MqFNaj7gmdl6",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concated_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "GeqiMGbXQyAU",
        "outputId": "d7b51a17-2b59-4f16-d180-78088acb1a48"
      },
      "id": "GeqiMGbXQyAU",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             City State      Zip                            Bank BankState  \\\n",
              "0             NaN   NaN      NaN                             NaN       NaN   \n",
              "1             NaN   NaN      NaN                             NaN       NaN   \n",
              "2             NaN   NaN      NaN                             NaN       NaN   \n",
              "3             NaN   NaN      NaN                             NaN       NaN   \n",
              "4             NaN   NaN      NaN                             NaN       NaN   \n",
              "...           ...   ...      ...                             ...       ...   \n",
              "624103  ENGLEWOOD    CO  80121.0     WELLS FARGO BANK NATL ASSOC        CO   \n",
              "707879     EUCLID    OH  44123.0        CITIZENS BANK NATL ASSOC        RI   \n",
              "15752   Greenwood    IN  46142.0  PNC BANK, NATIONAL ASSOCIATION        DE   \n",
              "696541  WINNEBAGO    IL  61088.0  PNC BANK, NATIONAL ASSOCIATION        IL   \n",
              "635320   GLENVIEW    IL  60026.0  JPMORGAN CHASE BANK NATL ASSOC        IL   \n",
              "\n",
              "           NAICS  Term  NoEmp  NewExist  CreateJob  RetainedJob  \\\n",
              "0            NaN   NaN    NaN       NaN        NaN          NaN   \n",
              "1            NaN   NaN    NaN       NaN        NaN          NaN   \n",
              "2            NaN   NaN    NaN       NaN        NaN          NaN   \n",
              "3            NaN   NaN    NaN       NaN        NaN          NaN   \n",
              "4            NaN   NaN    NaN       NaN        NaN          NaN   \n",
              "...          ...   ...    ...       ...        ...          ...   \n",
              "624103       0.0   9.0   39.0       0.0        0.0          0.0   \n",
              "707879  445110.0  54.0    5.0       0.0        0.0          5.0   \n",
              "15752   713120.0   7.0    2.0       1.0       13.0          2.0   \n",
              "696541       0.0  60.0    5.0       1.0        0.0          0.0   \n",
              "635320  722110.0  84.0    9.0       0.0        2.0          9.0   \n",
              "\n",
              "        FranchiseCode RevLineCr LowDoc  DisbursementGross  BalanceGross  \\\n",
              "0                 NaN       NaN    NaN                NaN           NaN   \n",
              "1                 NaN       NaN    NaN                NaN           NaN   \n",
              "2                 NaN       NaN    NaN                NaN           NaN   \n",
              "3                 NaN       NaN    NaN                NaN           NaN   \n",
              "4                 NaN       NaN    NaN                NaN           NaN   \n",
              "...               ...       ...    ...                ...           ...   \n",
              "624103            1.0         0      0           145000.0           0.0   \n",
              "707879            0.0         1      0           199787.0           0.0   \n",
              "15752             0.0         0      0           195000.0           0.0   \n",
              "696541            1.0         0      1            30000.0           0.0   \n",
              "635320            0.0         1      0            85000.0           0.0   \n",
              "\n",
              "          GrAppv  SBA_Appv  MIS_Status  \n",
              "0            NaN       NaN         NaN  \n",
              "1            NaN       NaN         NaN  \n",
              "2            NaN       NaN         NaN  \n",
              "3            NaN       NaN         NaN  \n",
              "4            NaN       NaN         NaN  \n",
              "...          ...       ...         ...  \n",
              "624103  145000.0  130500.0         0.0  \n",
              "707879   62000.0   31000.0         1.0  \n",
              "15752   195000.0   97500.0         1.0  \n",
              "696541   30000.0   24000.0         0.0  \n",
              "635320   85000.0   42500.0         0.0  \n",
              "\n",
              "[7842 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59fc132b-042f-4569-be5d-3af022d1608b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Zip</th>\n",
              "      <th>Bank</th>\n",
              "      <th>BankState</th>\n",
              "      <th>NAICS</th>\n",
              "      <th>Term</th>\n",
              "      <th>NoEmp</th>\n",
              "      <th>NewExist</th>\n",
              "      <th>CreateJob</th>\n",
              "      <th>RetainedJob</th>\n",
              "      <th>FranchiseCode</th>\n",
              "      <th>RevLineCr</th>\n",
              "      <th>LowDoc</th>\n",
              "      <th>DisbursementGross</th>\n",
              "      <th>BalanceGross</th>\n",
              "      <th>GrAppv</th>\n",
              "      <th>SBA_Appv</th>\n",
              "      <th>MIS_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624103</th>\n",
              "      <td>ENGLEWOOD</td>\n",
              "      <td>CO</td>\n",
              "      <td>80121.0</td>\n",
              "      <td>WELLS FARGO BANK NATL ASSOC</td>\n",
              "      <td>CO</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>145000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145000.0</td>\n",
              "      <td>130500.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>707879</th>\n",
              "      <td>EUCLID</td>\n",
              "      <td>OH</td>\n",
              "      <td>44123.0</td>\n",
              "      <td>CITIZENS BANK NATL ASSOC</td>\n",
              "      <td>RI</td>\n",
              "      <td>445110.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>199787.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62000.0</td>\n",
              "      <td>31000.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15752</th>\n",
              "      <td>Greenwood</td>\n",
              "      <td>IN</td>\n",
              "      <td>46142.0</td>\n",
              "      <td>PNC BANK, NATIONAL ASSOCIATION</td>\n",
              "      <td>DE</td>\n",
              "      <td>713120.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>195000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195000.0</td>\n",
              "      <td>97500.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696541</th>\n",
              "      <td>WINNEBAGO</td>\n",
              "      <td>IL</td>\n",
              "      <td>61088.0</td>\n",
              "      <td>PNC BANK, NATIONAL ASSOCIATION</td>\n",
              "      <td>IL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>30000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30000.0</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635320</th>\n",
              "      <td>GLENVIEW</td>\n",
              "      <td>IL</td>\n",
              "      <td>60026.0</td>\n",
              "      <td>JPMORGAN CHASE BANK NATL ASSOC</td>\n",
              "      <td>IL</td>\n",
              "      <td>722110.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>85000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85000.0</td>\n",
              "      <td>42500.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7842 rows  19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59fc132b-042f-4569-be5d-3af022d1608b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59fc132b-042f-4569-be5d-3af022d1608b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59fc132b-042f-4569-be5d-3af022d1608b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concated_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Eup0eQq2di",
        "outputId": "8387cb52-322c-45e1-9d48-e0d57528b8eb"
      },
      "id": "p1Eup0eQq2di",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['UrbanRural_0', 'UrbanRural_1', 'UrbanRural_2', 'City', 'State', 'Zip',\n",
              "       'Bank', 'BankState', 'NAICS', 'Term', 'NoEmp', 'NewExist', 'CreateJob',\n",
              "       'RetainedJob', 'FranchiseCode', 'RevLineCr', 'LowDoc',\n",
              "       'DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv',\n",
              "       'MIS_Status'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from category_encoders import BinaryEncoder\n",
        "import pandas as pd\n",
        "bin_encoder = BinaryEncoder(cols=cat_cols_bin_en)\n",
        "bin_encoded_data = bin_encoder.fit_transform(processed_data)"
      ],
      "metadata": {
        "id": "mNqOdrJRkIlK"
      },
      "id": "mNqOdrJRkIlK",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bin_encoded_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oqPOXOgm8uC",
        "outputId": "9e9a284e-ee88-4274-ffc2-a79d39a6b791"
      },
      "id": "3oqPOXOgm8uC",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['City_0', 'City_1', 'City_2', 'City_3', 'City_4', 'City_5', 'City_6',\n",
              "       'City_7', 'City_8', 'City_9', 'City_10', 'City_11', 'City_12',\n",
              "       'City_13', 'City_14', 'State_0', 'State_1', 'State_2', 'State_3',\n",
              "       'State_4', 'State_5', 'Zip_0', 'Zip_1', 'Zip_2', 'Zip_3', 'Zip_4',\n",
              "       'Zip_5', 'Zip_6', 'Zip_7', 'Zip_8', 'Zip_9', 'Zip_10', 'Zip_11',\n",
              "       'Zip_12', 'Zip_13', 'Zip_14', 'Bank_0', 'Bank_1', 'Bank_2', 'Bank_3',\n",
              "       'Bank_4', 'Bank_5', 'Bank_6', 'Bank_7', 'Bank_8', 'Bank_9', 'Bank_10',\n",
              "       'Bank_11', 'Bank_12', 'BankState_0', 'BankState_1', 'BankState_2',\n",
              "       'BankState_3', 'BankState_4', 'BankState_5', 'NAICS_0', 'NAICS_1',\n",
              "       'NAICS_2', 'NAICS_3', 'NAICS_4', 'NAICS_5', 'NAICS_6', 'NAICS_7',\n",
              "       'NAICS_8', 'NAICS_9', 'NAICS_10', 'Term', 'NoEmp', 'NewExist',\n",
              "       'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural_0',\n",
              "       'UrbanRural_1', 'RevLineCr', 'LowDoc', 'DisbursementGross',\n",
              "       'BalanceGross', 'GrAppv', 'SBA_Appv', 'MIS_Status'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = bin_encoded_data"
      ],
      "metadata": {
        "id": "TGk8qTn1k-zg"
      },
      "id": "TGk8qTn1k-zg",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4fef1d2e",
      "metadata": {
        "id": "4fef1d2e"
      },
      "outputs": [],
      "source": [
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# import numpy as np\n",
        "# # ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "# # X_transformed = np.array(ct.fit_transform(X))\n",
        "# encoded_data = pd.get_dummies(s_processed_data, columns=cat_cols)\n",
        "# encoded_data.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = encoded_data.iloc[:, :-1].values\n",
        "y = encoded_data.iloc[:, -1].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44)"
      ],
      "metadata": {
        "id": "DwREpI5SEtJw"
      },
      "id": "DwREpI5SEtJw",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data['MIS_Status'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX-lAPczpE56",
        "outputId": "4384bcc5-8a84-4d0d-f859-f1e15be3e0f2"
      },
      "id": "IX-lAPczpE56",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb0bfa4",
      "metadata": {
        "id": "7bb0bfa4"
      },
      "source": [
        "# Model Training\n",
        "\n",
        "See Project summary for types of models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "265acf5d",
      "metadata": {
        "id": "265acf5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac06f132-63e3-42b9-ba55-80b178c5454e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8294606761633913\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "# evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ced690c6",
      "metadata": {
        "id": "ced690c6"
      },
      "source": [
        "## Model Tuning\n",
        "\n",
        "Choose one model from the above list. You should provide reasoning on why you have picked the model over others. Perform tuning for the selected model:\n",
        "- Hyper-parameter tuning. Your hyper-parameter search space should have at least 50 combinations.\n",
        "- To avoid overfitting and provide you with reasonable estimate of model performance on hold-out dataset, you will need to split your dataset as following:\n",
        "    - Train, will be used to train model\n",
        "    - Validation, will be used to validate model each round of training\n",
        "    - Testing, will be used to provide final performance metrics, used only once on the final model\n",
        "- Feature engineering. See project description\n",
        "\n",
        "**Selelct final model that produces best performance on the Test dataset.**\n",
        "- For the best model, calculate probability threshold to maximize F1. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "674ab5b8",
      "metadata": {
        "id": "674ab5b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27776fd7-c320-4974-f8ab-343e9b90a103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "logreg = LogisticRegression()\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
        "# Define the hyperparameter search space\n",
        "param_grid = {\n",
        "    'penalty': ['l2', 'elasticnet', 'none'],\n",
        "    'C': [0.01, 0.1, 1.0],\n",
        "    'fit_intercept': [True, False],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'saga'],\n",
        "    'max_iter': [100]\n",
        "}\n",
        "\n",
        "# Define the GridSearchCV object\n",
        "grid_search = GridSearchCV(logreg, param_grid, cv=2, n_jobs=-1, verbose=1, \n",
        "                           scoring='accuracy')\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "val_score = grid_search.score(X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Validation score: {val_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGDpXEJeefbS",
        "outputId": "b37aa60c-ec53-4eb0-96cf-9f1081a1128e"
      },
      "id": "mGDpXEJeefbS",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "Validation score: 0.850360060189166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "score = best_model.score(X_test, y_test)\n",
        "\n",
        "print(\"Best model score:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OoK_cWJfdHt",
        "outputId": "283c3f14-ff8c-4a06-bd26-d31dbd071bae"
      },
      "id": "1OoK_cWJfdHt",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model score: 0.8517082626605282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30bc381c",
      "metadata": {
        "id": "30bc381c"
      },
      "source": [
        "## Save all artifacts\n",
        "\n",
        "Save all artifacts needed for scoring function:\n",
        "- Trained model\n",
        "- Encoders\n",
        "- Any other arficats you will need for scoring\n",
        "\n",
        "**You should stop your notebook here. Scoring function should be in a separate file/notebook.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib"
      ],
      "metadata": {
        "id": "RvBQh5pBf3At"
      },
      "id": "RvBQh5pBf3At",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('project_1_nallam_encoded_data.pkl', 'wb') as f1:\n",
        "    pickle.dump(encoded_data, f1)\n",
        "with open('project_1_nallam_best_model.pkl', 'wb') as f2:\n",
        "    pickle.dump(best_model, f2)\n",
        "with open('project_1_nallam_encoder.pkl', 'wb') as f3:\n",
        "    pickle.dump(bin_encoder, f3)"
      ],
      "metadata": {
        "id": "WhEGhfNPhBAx"
      },
      "id": "WhEGhfNPhBAx",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b556b0fe",
      "metadata": {
        "id": "b556b0fe"
      },
      "source": [
        "## Stop Here. Create new file/notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21ded0cd",
      "metadata": {
        "id": "21ded0cd"
      },
      "source": [
        "## =============================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c327c4",
      "metadata": {
        "id": "b7c327c4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "213f71c6",
      "metadata": {
        "id": "213f71c6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a0d2e830",
      "metadata": {
        "id": "a0d2e830"
      },
      "source": [
        "## Model Scoring\n",
        "\n",
        "Write function that will load artifacts from above, transform and score on a new dataset.\n",
        "Your function should return Python list of labels. For example: [0,1,0,1,1,0,0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1929ab",
      "metadata": {
        "id": "ae1929ab"
      },
      "outputs": [],
      "source": [
        "def project_1_scoring(data):\n",
        "    \"\"\"\n",
        "    Function to score input dataset.\n",
        "    \n",
        "    Input: dataset in Pandas DataFrame format\n",
        "    Output: Python list of labels in the same order as input records\n",
        "    \n",
        "    Flow:\n",
        "        - Load artifacts\n",
        "        - Transform dataset\n",
        "        - Score dataset\n",
        "        - Return pandas DF with following columns:\n",
        "            - index\n",
        "            - label\n",
        "            - probability_0\n",
        "            - probability_1\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc128b9",
      "metadata": {
        "id": "3cc128b9"
      },
      "outputs": [],
      "source": [
        "class GetTrainedModel:\n",
        "  def __init__(self, data):\n",
        "    # remove index\n",
        "    processed_data = data.loc[:,data.columns!='index']\n",
        "\n",
        "    def dollar_string_to_float(dollar_str):\n",
        "      dollar_str = dollar_str.replace(',', '')\n",
        "      dollar_float = float(dollar_str[1:])\n",
        "      return dollar_float\n",
        "    # converting dollar to float\n",
        "    currency_cols = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
        "    for colname in currency_cols:\n",
        "      processed_data[colname] = processed_data[colname].apply(dollar_string_to_float)\n",
        "\n",
        "    processed_data = processed_data.dropna()\n",
        "    \n",
        "    processed_data['MIS_Status'] = processed_data['MIS_Status'].replace('P I F', 0)\n",
        "    processed_data['MIS_Status'] = processed_data['MIS_Status'].replace('CHGOFF', 1)\n",
        "\n",
        "    processed_data['RevLineCr'] = processed_data['RevLineCr'].replace('N', 0)\n",
        "    processed_data['RevLineCr'] = processed_data['RevLineCr'].replace('0', 0)\n",
        "    processed_data['RevLineCr'] = processed_data['RevLineCr'].replace('Y', 1)\n",
        "    for remove_cat in processed_data['RevLineCr'].cat.categories.tolist():\n",
        "      if remove_cat not in [0,1]:\n",
        "        processed_data = processed_data[processed_data['RevLineCr'] != remove_cat]\n",
        "        processed_data['RevLineCr'] = processed_data['RevLineCr'].cat.remove_categories(remove_cat)\n",
        "\n",
        "    processed_data['NewExist'] = processed_data['NewExist'].replace(1, 0)\n",
        "    processed_data['NewExist'] = processed_data['NewExist'].replace(2, 1)\n",
        "    \n",
        "    processed_data['LowDoc'] = processed_data['LowDoc'].replace('Y', 1)\n",
        "    processed_data['LowDoc'] = processed_data['LowDoc'].replace('N', 0)\n",
        "    processed_data['LowDoc'] = processed_data['LowDoc'].replace('0', 0)\n",
        "    processed_data['LowDoc'] = processed_data['LowDoc'].replace('1', 1)\n",
        "    for remove_cat in processed_data['LowDoc'].cat.categories.tolist():\n",
        "      if remove_cat not in [0,1]:\n",
        "        processed_data = processed_data[processed_data['LowDoc'] != remove_cat]\n",
        "        processed_data['LowDoc'] = processed_data['LowDoc'].cat.remove_categories(remove_cat)\n",
        "    processed_data['LowDoc'].value_counts()\n",
        "\n",
        "    s_processed_data = processed_data.sample(frac=0.5, random_state=27)\n",
        "\n",
        "    cat_cols_bin_en = ['City', 'State', 'Bank', 'BankState', 'Zip', 'NAICS', 'UrbanRural']\n",
        "\n",
        "    from category_encoders import BinaryEncoder\n",
        "    import pandas as pd\n",
        "    bin_encoder = BinaryEncoder(cols=cat_cols_bin_en)\n",
        "    bin_encoded_data = bin_encoder.fit_transform(processed_data)\n",
        "\n",
        "    encoded_data = bin_encoded_data\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X = encoded_data.iloc[:, :-1].values\n",
        "    y = encoded_data.iloc[:, -1].values\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=44)\n",
        "\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "    lr_model = LogisticRegression('C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg')\n",
        "    lr_model.fit(X_train, y_train)\n",
        "\n",
        "    return lr_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16157e5c",
      "metadata": {
        "id": "16157e5c"
      },
      "source": [
        "### Example of Scoring function\n",
        "\n",
        "Don't copy the code as is. It is provided as an example only. \n",
        "- Function `train_model` - you need to focus on model and artifacts saving:\n",
        "    ```\n",
        "    pickle.dump(obj=artifacts_dict, file=artifacts_dict_file)\n",
        "    ```\n",
        "- Function `project_1_scoring` - you should have similar function with name `project_1_scoring`. The function will:\n",
        "    - Get Pandas dataframe as parameter\n",
        "    - Will load model and all needed encoders\n",
        "    - Will perform needed manipulations on the input Pandas DF - in the exact same format as input file for the project, minus MIS_Status feature\n",
        "    - Return Pandas DataFrame\n",
        "        - record index\n",
        "        - predicted class for threshold maximizing F1\n",
        "        - probability for class 0 (PIF)\n",
        "        - probability for class 1 (CHGOFF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b37c9dd",
      "metadata": {
        "id": "2b37c9dd"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Don't copy of use the cell code in any way!!!\n",
        "The code is provided as an example of generating artifacts for scoring function\n",
        "Your scoring function code should not have model training part!!!!\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def train_model(data):\n",
        "    \"\"\"\n",
        "    Train sample model and save artifacts\n",
        "    \"\"\"\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    from copy import deepcopy\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    import pickle\n",
        "    from sklearn.impute import SimpleImputer\n",
        "    \n",
        "    target_col = \"Survived\"\n",
        "    cols_to_drop = ['Name', 'Ticket', 'Cabin','SibSp', 'Parch', 'Sex','Embarked','PassengerId','Survived']\n",
        "    y = data[target_col]\n",
        "    X = data.drop(columns=[target_col])\n",
        "    \n",
        "    # Impute Embarked\n",
        "    X['Embarked'].replace(np.NaN, 'S',inplace = True)\n",
        "    \n",
        "    # Create new feature\n",
        "    X['FamilySize'] = X['SibSp'] + X['Parch']\n",
        "    \n",
        "    # Mean impute Age\n",
        "    imp_age_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "    imp_age_mean.fit(X[['Age']])\n",
        "    X['Age'] = imp_age_mean.transform(X[['Age']])\n",
        "\n",
        "\n",
        "    ohe_orig_columns = [\"Embarked\",\"Sex\"]\n",
        "    cat_encoders = {}\n",
        "    for col in ohe_orig_columns:\n",
        "        enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "        enc.fit(X[[col]])\n",
        "        result = enc.transform(X[[col]])\n",
        "        ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
        "        result_train = pd.DataFrame(result, columns=ohe_columns)\n",
        "        X= pd.concat([X, result_train], axis=1)\n",
        "        cat_encoders[col] = [deepcopy(enc),\"ohe\"]\n",
        "        \n",
        "    clf = LogisticRegression(max_iter=1000, random_state=0)\n",
        "    \n",
        "    columns_to_train = [x for x in X.columns if x not in cols_to_drop]\n",
        "    clf.fit(X[columns_to_train], y)\n",
        "    \n",
        "    # Todo: Add code to calculate optimal threshold. Replace 0.5 !!!!!\n",
        "    threshold = 0.5\n",
        "    # End Todo\n",
        "    \n",
        "    artifacts_dict = {\n",
        "        \"model\": clf,\n",
        "        \"cat_encoders\": cat_encoders,\n",
        "        \"imp_age_mean\": imp_age_mean,\n",
        "        \"ohe_columns\": ohe_orig_columns,\n",
        "        \"columns_to_train\":columns_to_train,\n",
        "        \"threshold\": threshold\n",
        "    }\n",
        "    artifacts_dict_file = open(\"./artifacts/artifacts_dict_file.pkl\", \"wb\")\n",
        "    pickle.dump(obj=artifacts_dict, file=artifacts_dict_file)\n",
        "    \n",
        "    artifacts_dict_file.close()    \n",
        "    return clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "719dcec9",
      "metadata": {
        "id": "719dcec9",
        "outputId": "93c2dcbc-dc7d-484f-9cac-f3ee7757ca51"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(max_iter=1000, random_state=0)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = pd.read_csv('titanic.csv')\n",
        "train_model(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa88cb35",
      "metadata": {
        "id": "aa88cb35"
      },
      "source": [
        "### Example scoring function\n",
        "\n",
        "This is example only. Don't copy code as is!!!   \n",
        "You must place scoring function in a separate Python file or Jupyter notebook.   \n",
        "\n",
        "**Don't place function in the same notebook as rest of the code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d3d7f8",
      "metadata": {
        "id": "46d3d7f8"
      },
      "outputs": [],
      "source": [
        "def project_1_scoring(data):\n",
        "    \"\"\"\n",
        "    Function to score input dataset.\n",
        "    \n",
        "    Input: dataset in Pandas DataFrame format\n",
        "    Output: Python list of labels in the same order as input records\n",
        "    \n",
        "    Flow:\n",
        "        - Load artifacts\n",
        "        - Transform dataset\n",
        "        - Score dataset\n",
        "        - Return labels\n",
        "    \n",
        "    \"\"\"\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    from copy import deepcopy\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    import pickle\n",
        "    \n",
        "    X = data.copy()\n",
        "    \n",
        "    '''Load Artifacts'''\n",
        "    artifacts_dict_file = open(\"./artifacts/artifacts_dict_file.pkl\", \"rb\")\n",
        "    artifacts_dict = pickle.load(file=artifacts_dict_file)\n",
        "    artifacts_dict_file.close()\n",
        "    \n",
        "    clf = artifacts_dict[\"model\"]\n",
        "    cat_encoders = artifacts_dict[\"cat_encoders\"]\n",
        "    imp_age_mean = artifacts_dict[\"imp_age_mean\"]\n",
        "    ohe_columns = artifacts_dict[\"ohe_columns\"]\n",
        "    columns_to_score = artifacts_dict[\"columns_to_train\"]\n",
        "    threshold = artifacts_dict[\"threshold\"]\n",
        "    \n",
        "    # Impute Embarked\n",
        "    X['Embarked'].replace(np.NaN, 'S',inplace = True)\n",
        "    \n",
        "    # Create new feature\n",
        "    X['FamilySize'] = X['SibSp'] + X['Parch']\n",
        "    \n",
        "    # Mean impute Age\n",
        "    X['Age'] = imp_age_mean.transform(X[['Age']])\n",
        "    \n",
        "    '''Encode categorical columns'''\n",
        "    for col in ohe_columns:\n",
        "        enc = cat_encoders[col][0]\n",
        "        result = enc.transform(X[[col]])\n",
        "        ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
        "        result_train = pd.DataFrame(result, columns=ohe_columns)\n",
        "        X = pd.concat([X, result_train], axis=1)\n",
        "        \n",
        "    y_pred_proba = clf.predict_proba(X[columns_to_score])\n",
        "    y_pred = (y_pred_proba[:,0] < threshold).astype(np.int16)\n",
        "    d = {\"index\":data[\"PassengerId\"],\n",
        "         \"label\":y_pred,\n",
        "         \"probability_0\":y_pred_proba[:,0],\n",
        "         \"probability_1\":y_pred_proba[:,1]}\n",
        "    \n",
        "    return pd.DataFrame(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd9dbc26",
      "metadata": {
        "id": "fd9dbc26",
        "outputId": "91e6d2f5-1502-475b-af52-2837566f52df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "      <th>probability_0</th>\n",
              "      <th>probability_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.901298</td>\n",
              "      <td>0.098702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.071879</td>\n",
              "      <td>0.928121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.367665</td>\n",
              "      <td>0.632335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.098564</td>\n",
              "      <td>0.901436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.923460</td>\n",
              "      <td>0.076540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  label  probability_0  probability_1\n",
              "0      1      0       0.901298       0.098702\n",
              "1      2      1       0.071879       0.928121\n",
              "2      3      1       0.367665       0.632335\n",
              "3      4      1       0.098564       0.901436\n",
              "4      5      0       0.923460       0.076540"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "project_1_scoring(df_train).head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}