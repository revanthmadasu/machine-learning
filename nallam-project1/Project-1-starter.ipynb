{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62834763",
   "metadata": {},
   "source": [
    "# Project 1 Starter\n",
    "\n",
    "**This is draft - version 0 - changes are possible and will be anounced.**\n",
    "\n",
    "Project 1 is to allow students to practice Data Science concepts learned so far.\n",
    "\n",
    "The project will include following tasks:\n",
    "- Load dataset. Don't use \"index\" column for training.\n",
    "- Clean up the data:\n",
    "    - Encode replace missing values\n",
    "    - Replace features values that appear incorrect\n",
    "- Encode categorical variables\n",
    "- Split dataset to Train/Validation/Test\n",
    "- Add engineered features\n",
    "- Train and tune ML model\n",
    "- Provide final metrics using Test dataset\n",
    "\n",
    "### Types of models to train\n",
    "\n",
    "Your final submission should include single model. \n",
    "The model set you should try to come up with best model:\n",
    "1. Sklearn Logistic Regression - try all combinations of regularization\n",
    "2. H2O-3 GLM - try different combinations of regularization\n",
    "\n",
    "\n",
    "\n",
    "### Feature engineering\n",
    "\n",
    "You should train/fit categorical features scalers and encoders on Train only. Use `transform` or equivalent function on Validation/Test datasets.\n",
    "\n",
    "It is important to understand all the steps before model training, so that you can reliably replicate and test them to produce scoring function.\n",
    "\n",
    "\n",
    "You should generate various new features. Examples of such features can be seen in the Module-3 lecture on GLMs.\n",
    "Your final model should have at least **10** new engineered features. On-hot-encoding, label encoding, and target encoding is not included in the **10** features.\n",
    "You can try, but target encoding is not expected to produce improvement for Linear models.\n",
    "\n",
    "Ideas for Feature engineering for various types of variables:\n",
    "1. https://docs.h2o.ai/driverless-ai/1-10-lts/docs/userguide/transformations.html\n",
    "2. GLM lecture and hands-on (Module-3)\n",
    "\n",
    "\n",
    "**Note**: \n",
    "- You don't have to perform feature engineering using H2O-3 even if you decided to use H2O-3 GLM for model training.\n",
    "- It is OK to perfor feature engineering using any technique, as long as you can replicate it correctly in the Scoring function.\n",
    "\n",
    "\n",
    "### Threshold calculation\n",
    "\n",
    "You will need to calculate optimal threshold for class assignment using F1 metric:\n",
    "- If using sklearn, use F1 `macro`: `f1_score(y_true, y_pred, average='macro')` \n",
    "- If using H2O-3, use F1\n",
    "\n",
    "You will need to find optimal probability threshold for class assignment, the threshold that maximizes above F1.\n",
    "\n",
    "\n",
    "\n",
    "### Scoring function\n",
    "\n",
    "The Project-1 will be graded based on the completeness and performance of your final model against the hold-out dataset.\n",
    "The hold-out dataset will not be known to the students. As part of your deliverables, you will need to submit a scoring function. The scoring function will perform the following:\n",
    "- Accept dataset in the same format as provided with the project, minus \"MIS_Status\" column\n",
    "- Load trained model and any encoders/scalers that are needed to transform data\n",
    "- Transform dataset into format that can be scored with the trained model\n",
    "- Score the dataset and return the results, for each record\n",
    "    - Record ID\n",
    "    - Record label as determined by final model (0 or 1)\n",
    "    - If your model returns probabilities, you need to assign the label based on maximum F1 threshold\n",
    "    \n",
    "Scoring function header:\n",
    "```\n",
    "def project_1_scoring(data):\n",
    "    \"\"\"\n",
    "    Function to score input dataset.\n",
    "    \n",
    "    Input: dataset in Pandas DataFrame format\n",
    "    Output: Python list of labels in the same order as input records\n",
    "    \n",
    "    Flow:\n",
    "        - Load artifacts\n",
    "        - Transform dataset\n",
    "        - Score dataset\n",
    "        - Return labels\n",
    "    \n",
    "    \"\"\"\n",
    "    l = data.shape[0]\n",
    "    return l*[0]\n",
    "```\n",
    "\n",
    "Look for full example of scoring function at the bottom of the notebook. **Don't copy as is - this is just an example**\n",
    "\n",
    "\n",
    "\n",
    "### Deliverables in a single zip file in the following structure:\n",
    "- `notebook` (folder)\n",
    "    - Jupyter notebook with complete code to manipulate data, train and tune final model. `ipynb` format\n",
    "    - Jupyter notebook in `html` format\n",
    "- `artifacts` (folder)\n",
    "    - Model and any potential encoders in the \"pkl\" format or native H2O-3 format (for H2O-3 model)\n",
    "    - Scoring function that will load the final model and encoders. Separate from above notebook or `.py` file\n",
    "\n",
    "\n",
    "\n",
    "Your notebook should include explanations about your code and be designed to be easily followed and results replicated. Once you are done with the final version, you will need to test it by running all cells from top to bottom after restarting Kernel. It can be done by running `Kernel -> Restart & Run All`\n",
    "\n",
    "\n",
    "**Important**: To speed up progress, first produce working code using a small subset of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeaf5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c341cb74",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "The dataset is from the U.S. Small Business Administration (SBA) The U.S. SBA was founded in 1953 on the principle of promoting and assisting small enterprises in the U.S. credit market (SBA Overview and History, US Small Business Administration (2015)). Small businesses have been a primary source of job creation in the United States; therefore, fostering small business formation and growth has social benefits by creating job opportunities and reducing unemployment. There have been many success stories of start-ups receiving SBA loan guarantees such as FedEx and Apple Computer. However, there have also been stories of small businesses and/or start-ups that have defaulted on their SBA-guaranteed loans.  \n",
    "More info on the original dataset: https://www.kaggle.com/mirbektoktogaraev/should-this-loan-be-approved-or-denied\n",
    "\n",
    "**Don't use original dataset, use only dataset provided with project requirements in eLearning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9b618",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Use dataset provided in the eLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca7e035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Extend cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb889838",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon Mar 18 18:25:50 2019\n",
    "\n",
    "@author: Uri Smashnov\n",
    "\n",
    "Purpose: Analyze input Pandas DataFrame and return stats per column\n",
    "Details: The function calculates levels for categorical variables and allows to analyze summarized information\n",
    "\n",
    "To view wide table set following Pandas options:\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth',200)\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "def describe_more(df,normalize_ind=False, weight_column=None, skip_columns=[], dropna=True):\n",
    "    var = [] ; l = [] ; t = []; unq =[]; min_l = []; max_l = [];\n",
    "    assert isinstance(skip_columns, list), \"Argument skip_columns should be list\"\n",
    "    if weight_column is not None:\n",
    "        if weight_column not in list(df.columns):\n",
    "            raise AssertionError('weight_column is not a valid column name in the input DataFrame')\n",
    "      \n",
    "    for x in df:\n",
    "        if x in skip_columns:\n",
    "            pass\n",
    "        else:\n",
    "            var.append( x )\n",
    "            uniq_counts = len(pd.value_counts(df[x],dropna=dropna))\n",
    "            uniq_counts = len(pd.value_counts(df[x], dropna=dropna)[pd.value_counts(df[x],dropna=dropna)>0])\n",
    "            l.append(uniq_counts)\n",
    "            t.append( df[ x ].dtypes )\n",
    "            min_l.append(df[x].apply(str).str.len().min())\n",
    "            max_l.append(df[x].apply(str).str.len().max())\n",
    "            if weight_column is not None and x not in skip_columns:\n",
    "                df2 = df.groupby(x).agg({weight_column: 'sum'}).sort_values(weight_column, ascending=False)\n",
    "                df2['authtrans_vts_cnt']=((df2[weight_column])/df2[weight_column].sum()).round(2)\n",
    "                unq.append(df2.head(n=100).to_dict()[weight_column])\n",
    "            else:\n",
    "                df_cat_d = df[x].value_counts(normalize=normalize_ind,dropna=dropna).round(decimals=2)\n",
    "                df_cat_d = df_cat_d[df_cat_d>0]\n",
    "                #unq.append(df[x].value_counts().iloc[0:100].to_dict())\n",
    "                unq.append(df_cat_d.iloc[0:100].to_dict())\n",
    "            \n",
    "    levels = pd.DataFrame( { 'A_Variable' : var , 'Levels' : l , 'Datatype' : t ,\n",
    "                             'Min Length' : min_l,\n",
    "                             'Max Length': max_l,\n",
    "                             'Level_Values' : unq} )\n",
    "    #levels.sort_values( by = 'Levels' , inplace = True )\n",
    "    return levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2c254",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a19bd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/SBA_loans_project_1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2301a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (809247, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b4aea",
   "metadata": {},
   "source": [
    "**Review dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547f9eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_Variable</th>\n",
       "      <th>Levels</th>\n",
       "      <th>Datatype</th>\n",
       "      <th>Min Length</th>\n",
       "      <th>Max Length</th>\n",
       "      <th>Level_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index</td>\n",
       "      <td>809247</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>{0: 1, 539491: 1, 539493: 1, 539494: 1, 539495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City</td>\n",
       "      <td>31320</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>{'LOS ANGELES': 10372, 'HOUSTON': 9260, 'NEW Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State</td>\n",
       "      <td>51</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'CA': 117341, 'TX': 63425, 'NY': 51877, 'FL':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zip</td>\n",
       "      <td>32731</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{10001: 841, 90015: 830, 93401: 729, 90010: 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bank</td>\n",
       "      <td>5716</td>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>{'BANK OF AMERICA NATL ASSOC': 78111, 'WELLS F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BankState</td>\n",
       "      <td>55</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'CA': 106293, 'NC': 71557, 'IL': 59258, 'OH':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NAICS</td>\n",
       "      <td>1307</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>{0: 181845, 722110: 25217, 722211: 17476, 8111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Term</td>\n",
       "      <td>407</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{84: 207228, 60: 80965, 240: 77385, 120: 69852...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NoEmp</td>\n",
       "      <td>581</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{1: 138836, 2: 124470, 3: 81466, 4: 66306, 5: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NewExist</td>\n",
       "      <td>3</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{1.0: 580478, 2.0: 227709, 0.0: 932}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CreateJob</td>\n",
       "      <td>234</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 566148, 1: 56789, 2: 52162, 3: 25945, 4: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RetainedJob</td>\n",
       "      <td>345</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 396287, 1: 79893, 2: 69149, 3: 44941, 4: 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FranchiseCode</td>\n",
       "      <td>2684</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{1: 574731, 0: 187961, 78760: 3043, 68020: 173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UrbanRural</td>\n",
       "      <td>3</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 423681, 0: 290804, 2: 94762}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RevLineCr</td>\n",
       "      <td>16</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'N': 378424, '0': 231967, 'Y': 181011, 'T': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LowDoc</td>\n",
       "      <td>8</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'N': 704515, 'Y': 99339, '0': 1343, 'C': 681,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DisbursementGross</td>\n",
       "      <td>110579</td>\n",
       "      <td>object</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>{'$50,000.00 ': 39328, '$100,000.00 ': 33116, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BalanceGross</td>\n",
       "      <td>13</td>\n",
       "      <td>object</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>{'$0.00 ': 809235, '$41,509.00 ': 1, '$115,820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GrAppv</td>\n",
       "      <td>20724</td>\n",
       "      <td>object</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>{'$50,000.00 ': 62264, '$25,000.00 ': 46168, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SBA_Appv</td>\n",
       "      <td>35896</td>\n",
       "      <td>object</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>{'$25,000.00 ': 44418, '$12,500.00 ': 36115, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MIS_Status</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>{'P I F': 665576, 'CHGOFF': 141849}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A_Variable  Levels Datatype  Min Length  Max Length  \\\n",
       "0               index  809247    int64           1           6   \n",
       "1                City   31320   object           1          30   \n",
       "2               State      51   object           2           3   \n",
       "3                 Zip   32731    int64           1           5   \n",
       "4                Bank    5716   object           3          30   \n",
       "5           BankState      55   object           2           3   \n",
       "6               NAICS    1307    int64           1           6   \n",
       "7                Term     407    int64           1           3   \n",
       "8               NoEmp     581    int64           1           4   \n",
       "9            NewExist       3  float64           3           3   \n",
       "10          CreateJob     234    int64           1           4   \n",
       "11        RetainedJob     345    int64           1           4   \n",
       "12      FranchiseCode    2684    int64           1           5   \n",
       "13         UrbanRural       3    int64           1           1   \n",
       "14          RevLineCr      16   object           1           3   \n",
       "15             LowDoc       8   object           1           3   \n",
       "16  DisbursementGross  110579   object           6          15   \n",
       "17       BalanceGross      13   object           6          12   \n",
       "18             GrAppv   20724   object           8          14   \n",
       "19           SBA_Appv   35896   object           8          14   \n",
       "20         MIS_Status       2   object           3           6   \n",
       "\n",
       "                                         Level_Values  \n",
       "0   {0: 1, 539491: 1, 539493: 1, 539494: 1, 539495...  \n",
       "1   {'LOS ANGELES': 10372, 'HOUSTON': 9260, 'NEW Y...  \n",
       "2   {'CA': 117341, 'TX': 63425, 'NY': 51877, 'FL':...  \n",
       "3   {10001: 841, 90015: 830, 93401: 729, 90010: 65...  \n",
       "4   {'BANK OF AMERICA NATL ASSOC': 78111, 'WELLS F...  \n",
       "5   {'CA': 106293, 'NC': 71557, 'IL': 59258, 'OH':...  \n",
       "6   {0: 181845, 722110: 25217, 722211: 17476, 8111...  \n",
       "7   {84: 207228, 60: 80965, 240: 77385, 120: 69852...  \n",
       "8   {1: 138836, 2: 124470, 3: 81466, 4: 66306, 5: ...  \n",
       "9                {1.0: 580478, 2.0: 227709, 0.0: 932}  \n",
       "10  {0: 566148, 1: 56789, 2: 52162, 3: 25945, 4: 1...  \n",
       "11  {0: 396287, 1: 79893, 2: 69149, 3: 44941, 4: 3...  \n",
       "12  {1: 574731, 0: 187961, 78760: 3043, 68020: 173...  \n",
       "13                   {1: 423681, 0: 290804, 2: 94762}  \n",
       "14  {'N': 378424, '0': 231967, 'Y': 181011, 'T': 1...  \n",
       "15  {'N': 704515, 'Y': 99339, '0': 1343, 'C': 681,...  \n",
       "16  {'$50,000.00 ': 39328, '$100,000.00 ': 33116, ...  \n",
       "17  {'$0.00 ': 809235, '$41,509.00 ': 1, '$115,820...  \n",
       "18  {'$50,000.00 ': 62264, '$25,000.00 ': 46168, '...  \n",
       "19  {'$25,000.00 ': 44418, '$12,500.00 ': 36115, '...  \n",
       "20                {'P I F': 665576, 'CHGOFF': 141849}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df = describe_more(data)\n",
    "desc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1af41",
   "metadata": {},
   "source": [
    "## Dataset preparation and clean-up\n",
    "\n",
    "Modify and clean-up the dataset as following:\n",
    "- Replace encode Na/Null values\n",
    "- Convert the strings styled as '$XXXX.XX' to float values. Columns = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
    "- Convert MIS_Status to 0/1. Make value \"CHGOFF\" as 1\n",
    "\n",
    "Any additional clean-up as you find fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f9eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7f21dcf",
   "metadata": {},
   "source": [
    "## Categorical and numerical variables encoding\n",
    "\n",
    "Encode categorical variables using either one of the techniques below. Don't use LabelEncoder.\n",
    "- One-hot-encoder for variables with less than 10 valid values. Name your new columns \"Original_name\"_valid_value\n",
    "- Target encoder from the following library: https://contrib.scikit-learn.org/category_encoders/index.html . Name your new column \"Original_name\"_trg\n",
    "- WOE encoder from the following library: https://contrib.scikit-learn.org/category_encoders/index.html . Name your new column \"Original_name\"_woe\n",
    "\n",
    "\n",
    "WOE encoder can be used with numerical variables too. \n",
    "\n",
    "\n",
    "Example of use for target encoder:\n",
    "```\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.TargetEncoder(cols=[...])\n",
    "\n",
    "encoder.fit(X, y)\n",
    "X_cleaned = encoder.transform(X_dirty)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef1d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bb0bfa4",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "See Project summary for types of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265acf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ced690c6",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "Choose one model from the above list. You should provide reasoning on why you have picked the model over others. Perform tuning for the selected model:\n",
    "- Hyper-parameter tuning. Your hyper-parameter search space should have at least 50 combinations.\n",
    "- To avoid overfitting and provide you with reasonable estimate of model performance on hold-out dataset, you will need to split your dataset as following:\n",
    "    - Train, will be used to train model\n",
    "    - Validation, will be used to validate model each round of training\n",
    "    - Testing, will be used to provide final performance metrics, used only once on the final model\n",
    "- Feature engineering. See project description\n",
    "\n",
    "**Selelct final model that produces best performance on the Test dataset.**\n",
    "- For the best model, calculate probability threshold to maximize F1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ab5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30bc381c",
   "metadata": {},
   "source": [
    "## Save all artifacts\n",
    "\n",
    "Save all artifacts needed for scoring function:\n",
    "- Trained model\n",
    "- Encoders\n",
    "- Any other arficats you will need for scoring\n",
    "\n",
    "**You should stop your notebook here. Scoring function should be in a separate file/notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556b0fe",
   "metadata": {},
   "source": [
    "## Stop Here. Create new file/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ded0cd",
   "metadata": {},
   "source": [
    "## =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c327c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f71c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0d2e830",
   "metadata": {},
   "source": [
    "## Model Scoring\n",
    "\n",
    "Write function that will load artifacts from above, transform and score on a new dataset.\n",
    "Your function should return Python list of labels. For example: [0,1,0,1,1,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae1929ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_1_scoring(data):\n",
    "    \"\"\"\n",
    "    Function to score input dataset.\n",
    "    \n",
    "    Input: dataset in Pandas DataFrame format\n",
    "    Output: Python list of labels in the same order as input records\n",
    "    \n",
    "    Flow:\n",
    "        - Load artifacts\n",
    "        - Transform dataset\n",
    "        - Score dataset\n",
    "        - Return pandas DF with following columns:\n",
    "            - index\n",
    "            - label\n",
    "            - probability_0\n",
    "            - probability_1\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc128b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16157e5c",
   "metadata": {},
   "source": [
    "### Example of Scoring function\n",
    "\n",
    "Don't copy the code as is. It is provided as an example only. \n",
    "- Function `train_model` - you need to focus on model and artifacts saving:\n",
    "    ```\n",
    "    pickle.dump(obj=artifacts_dict, file=artifacts_dict_file)\n",
    "    ```\n",
    "- Function `project_1_scoring` - you should have similar function with name `project_1_scoring`. The function will:\n",
    "    - Get Pandas dataframe as parameter\n",
    "    - Will load model and all needed encoders\n",
    "    - Will perform needed manipulations on the input Pandas DF - in the exact same format as input file for the project, minus MIS_Status feature\n",
    "    - Return Pandas DataFrame\n",
    "        - record index\n",
    "        - predicted class for threshold maximizing F1\n",
    "        - probability for class 0 (PIF)\n",
    "        - probability for class 1 (CHGOFF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b37c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Don't copy of use the cell code in any way!!!\n",
    "The code is provided as an example of generating artifacts for scoring function\n",
    "Your scoring function code should not have model training part!!!!\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def train_model(data):\n",
    "    \"\"\"\n",
    "    Train sample model and save artifacts\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from copy import deepcopy\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import pickle\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    \n",
    "    target_col = \"Survived\"\n",
    "    cols_to_drop = ['Name', 'Ticket', 'Cabin','SibSp', 'Parch', 'Sex','Embarked','PassengerId','Survived']\n",
    "    y = data[target_col]\n",
    "    X = data.drop(columns=[target_col])\n",
    "    \n",
    "    # Impute Embarked\n",
    "    X['Embarked'].replace(np.NaN, 'S',inplace = True)\n",
    "    \n",
    "    # Create new feature\n",
    "    X['FamilySize'] = X['SibSp'] + X['Parch']\n",
    "    \n",
    "    # Mean impute Age\n",
    "    imp_age_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp_age_mean.fit(X[['Age']])\n",
    "    X['Age'] = imp_age_mean.transform(X[['Age']])\n",
    "\n",
    "\n",
    "    ohe_orig_columns = [\"Embarked\",\"Sex\"]\n",
    "    cat_encoders = {}\n",
    "    for col in ohe_orig_columns:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        enc.fit(X[[col]])\n",
    "        result = enc.transform(X[[col]])\n",
    "        ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
    "        result_train = pd.DataFrame(result, columns=ohe_columns)\n",
    "        X= pd.concat([X, result_train], axis=1)\n",
    "        cat_encoders[col] = [deepcopy(enc),\"ohe\"]\n",
    "        \n",
    "    clf = LogisticRegression(max_iter=1000, random_state=0)\n",
    "    \n",
    "    columns_to_train = [x for x in X.columns if x not in cols_to_drop]\n",
    "    clf.fit(X[columns_to_train], y)\n",
    "    \n",
    "    # Todo: Add code to calculate optimal threshold. Replace 0.5 !!!!!\n",
    "    threshold = 0.5\n",
    "    # End Todo\n",
    "    \n",
    "    artifacts_dict = {\n",
    "        \"model\": clf,\n",
    "        \"cat_encoders\": cat_encoders,\n",
    "        \"imp_age_mean\": imp_age_mean,\n",
    "        \"ohe_columns\": ohe_orig_columns,\n",
    "        \"columns_to_train\":columns_to_train,\n",
    "        \"threshold\": threshold\n",
    "    }\n",
    "    artifacts_dict_file = open(\"./artifacts/artifacts_dict_file.pkl\", \"wb\")\n",
    "    pickle.dump(obj=artifacts_dict, file=artifacts_dict_file)\n",
    "    \n",
    "    artifacts_dict_file.close()    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "719dcec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('titanic.csv')\n",
    "train_model(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88cb35",
   "metadata": {},
   "source": [
    "### Example scoring function\n",
    "\n",
    "This is example only. Don't copy code as is!!!   \n",
    "You must place scoring function in a separate Python file or Jupyter notebook.   \n",
    "\n",
    "**Don't place function in the same notebook as rest of the code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46d3d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_1_scoring(data):\n",
    "    \"\"\"\n",
    "    Function to score input dataset.\n",
    "    \n",
    "    Input: dataset in Pandas DataFrame format\n",
    "    Output: Python list of labels in the same order as input records\n",
    "    \n",
    "    Flow:\n",
    "        - Load artifacts\n",
    "        - Transform dataset\n",
    "        - Score dataset\n",
    "        - Return labels\n",
    "    \n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from copy import deepcopy\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import pickle\n",
    "    \n",
    "    X = data.copy()\n",
    "    \n",
    "    '''Load Artifacts'''\n",
    "    artifacts_dict_file = open(\"./artifacts/artifacts_dict_file.pkl\", \"rb\")\n",
    "    artifacts_dict = pickle.load(file=artifacts_dict_file)\n",
    "    artifacts_dict_file.close()\n",
    "    \n",
    "    clf = artifacts_dict[\"model\"]\n",
    "    cat_encoders = artifacts_dict[\"cat_encoders\"]\n",
    "    imp_age_mean = artifacts_dict[\"imp_age_mean\"]\n",
    "    ohe_columns = artifacts_dict[\"ohe_columns\"]\n",
    "    columns_to_score = artifacts_dict[\"columns_to_train\"]\n",
    "    threshold = artifacts_dict[\"threshold\"]\n",
    "    \n",
    "    # Impute Embarked\n",
    "    X['Embarked'].replace(np.NaN, 'S',inplace = True)\n",
    "    \n",
    "    # Create new feature\n",
    "    X['FamilySize'] = X['SibSp'] + X['Parch']\n",
    "    \n",
    "    # Mean impute Age\n",
    "    X['Age'] = imp_age_mean.transform(X[['Age']])\n",
    "    \n",
    "    '''Encode categorical columns'''\n",
    "    for col in ohe_columns:\n",
    "        enc = cat_encoders[col][0]\n",
    "        result = enc.transform(X[[col]])\n",
    "        ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
    "        result_train = pd.DataFrame(result, columns=ohe_columns)\n",
    "        X = pd.concat([X, result_train], axis=1)\n",
    "        \n",
    "    y_pred_proba = clf.predict_proba(X[columns_to_score])\n",
    "    y_pred = (y_pred_proba[:,0] < threshold).astype(np.int16)\n",
    "    d = {\"index\":data[\"PassengerId\"],\n",
    "         \"label\":y_pred,\n",
    "         \"probability_0\":y_pred_proba[:,0],\n",
    "         \"probability_1\":y_pred_proba[:,1]}\n",
    "    \n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9dbc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>probability_0</th>\n",
       "      <th>probability_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.901298</td>\n",
       "      <td>0.098702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071879</td>\n",
       "      <td>0.928121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367665</td>\n",
       "      <td>0.632335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098564</td>\n",
       "      <td>0.901436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923460</td>\n",
       "      <td>0.076540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  label  probability_0  probability_1\n",
       "0      1      0       0.901298       0.098702\n",
       "1      2      1       0.071879       0.928121\n",
       "2      3      1       0.367665       0.632335\n",
       "3      4      1       0.098564       0.901436\n",
       "4      5      0       0.923460       0.076540"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_1_scoring(df_train).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
